wandb_version: 1

_wandb:
  desc: null
  value:
    cli_version: 0.13.6
    framework: huggingface
    huggingface_version: 4.18.0
    is_jupyter_run: false
    is_kaggle_kernel: false
    python_version: 3.7.15
    start_time: 1723134210.270448
    t:
      1:
      - 1
      - 5
      - 11
      - 31
      - 41
      - 49
      - 51
      - 53
      - 55
      2:
      - 1
      - 5
      - 11
      - 31
      - 41
      - 49
      - 51
      - 53
      - 55
      3:
      - 1
      - 16
      - 23
      4: 3.7.15
      5: 0.13.6
      6: 4.18.0
      8:
      - 5
      9:
        2: simpletransformers
adafactor_beta1:
  desc: null
  value: null
adafactor_clip_threshold:
  desc: null
  value: 1.0
adafactor_decay_rate:
  desc: null
  value: -0.8
adafactor_eps:
  desc: null
  value:
  - 1.0e-30
  - 0.001
adafactor_relative_step:
  desc: null
  value: true
adafactor_scale_parameter:
  desc: null
  value: true
adafactor_warmup_init:
  desc: null
  value: true
adam_epsilon:
  desc: null
  value: 1.0e-08
best_model_dir:
  desc: null
  value: ./outputs/egret_pretrain_stage_1/bestoutput
block_size:
  desc: null
  value: 256
cache_dir:
  desc: null
  value: cache_dir/
clean_text:
  desc: null
  value: true
config:
  desc: null
  value:
    architectures:
    - BertForMaskedLM
    attention_probs_dropout_prob: 0.1
    hidden_act: gelu
    hidden_dropout_prob: 0.1
    hidden_size: 256
    initializer_range: 0.02
    intermediate_size: 512
    layer_norm_eps: 1.0e-12
    max_position_embeddings: 512
    model_type: bert
    num_attention_heads: 4
    num_hidden_layers: 12
    pad_token_id: 0
    type_vocab_size: 2
config_name:
  desc: null
  value: null
cosine_schedule_num_cycles:
  desc: null
  value: 0.5
custom_layer_parameters:
  desc: null
  value: []
custom_parameter_groups:
  desc: null
  value: []
dataloader_num_workers:
  desc: null
  value: 0
dataset_class:
  desc: null
  value: null
dataset_type:
  desc: null
  value: None
discriminator_config:
  desc: null
  value: {}
discriminator_loss_weight:
  desc: null
  value: 50.0
do_lower_case:
  desc: null
  value: false
dynamic_quantize:
  desc: null
  value: false
early_stopping_consider_epochs:
  desc: null
  value: false
early_stopping_delta:
  desc: null
  value: 0
early_stopping_metric:
  desc: null
  value: eval_loss
early_stopping_metric_minimize:
  desc: null
  value: true
early_stopping_patience:
  desc: null
  value: 3
encoding:
  desc: null
  value: null
eval_batch_size:
  desc: null
  value: 8
evaluate_during_training:
  desc: null
  value: true
evaluate_during_training_silent:
  desc: null
  value: true
evaluate_during_training_steps:
  desc: null
  value: 2000
evaluate_during_training_verbose:
  desc: null
  value: false
evaluate_each_epoch:
  desc: null
  value: true
fp16:
  desc: null
  value: false
generator_config:
  desc: null
  value: {}
gradient_accumulation_steps:
  desc: null
  value: 1
handle_chinese_chars:
  desc: null
  value: true
learning_rate:
  desc: null
  value: 0.0002
local_rank:
  desc: null
  value: -1
logging_steps:
  desc: null
  value: 50
manual_seed:
  desc: null
  value: 42
max_grad_norm:
  desc: null
  value: 1.0
max_seq_length:
  desc: null
  value: 256
max_steps:
  desc: null
  value: -1
min_frequency:
  desc: null
  value: 2
mlm:
  desc: null
  value: true
mlm_probability:
  desc: null
  value: 0.15
model_class:
  desc: null
  value: LanguageModelingModel
model_name:
  desc: null
  value: null
model_type:
  desc: null
  value: bert
multiprocessing_chunksize:
  desc: null
  value: -1
n_gpu:
  desc: null
  value: 1
no_cache:
  desc: null
  value: false
no_save:
  desc: null
  value: false
not_saved_args:
  desc: null
  value: []
num_train_epochs:
  desc: null
  value: 50
optimizer:
  desc: null
  value: AdamW
output_dir:
  desc: null
  value: ./outputs/egret_pretrain_stage_1/output
overwrite_output_dir:
  desc: null
  value: true
polynomial_decay_schedule_lr_end:
  desc: null
  value: 1.0e-07
polynomial_decay_schedule_power:
  desc: null
  value: 1.0
process_count:
  desc: null
  value: 6
quantized_model:
  desc: null
  value: false
reprocess_input_data:
  desc: null
  value: true
save_best_model:
  desc: null
  value: true
save_eval_checkpoints:
  desc: null
  value: true
save_model_every_epoch:
  desc: null
  value: true
save_optimizer_and_scheduler:
  desc: null
  value: true
save_steps:
  desc: null
  value: 2000
scheduler:
  desc: null
  value: linear_schedule_with_warmup
silent:
  desc: null
  value: false
skip_special_tokens:
  desc: null
  value: true
sliding_window:
  desc: null
  value: false
special_tokens:
  desc: null
  value:
  - <s>
  - <pad>
  - </s>
  - <unk>
  - <mask>
special_tokens_list:
  desc: null
  value: []
stride:
  desc: null
  value: 0.8
strip_accents:
  desc: null
  value: true
tensorboard_dir:
  desc: null
  value: null
thread_count:
  desc: null
  value: null
tie_generator_and_discriminator_embeddings:
  desc: null
  value: true
tokenizer_name:
  desc: null
  value: null
tokenizer_type:
  desc: null
  value: null
train_batch_size:
  desc: null
  value: 32
train_custom_parameters_only:
  desc: null
  value: false
use_cached_eval_features:
  desc: null
  value: false
use_early_stopping:
  desc: null
  value: false
use_hf_datasets:
  desc: null
  value: false
use_multiprocessing:
  desc: null
  value: true
use_multiprocessing_for_evaluation:
  desc: null
  value: true
vocab_size:
  desc: null
  value: null
wandb_kwargs:
  desc: null
  value: {}
wandb_project:
  desc: null
  value: egret_pretrain_stage_1
warmup_ratio:
  desc: null
  value: 0.06
warmup_steps:
  desc: null
  value: 45030
weight_decay:
  desc: null
  value: 0.0
